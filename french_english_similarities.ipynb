{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I´m trying to figure out how I can use my coding/ML skills to help me learn new languages. I know that it craves a lot of hard work to truly become proficient in a foreign language but I am interested in seeing if I can construct some shortcuts for myself. I know there are already apps out there like DuoLingo where people get paid to do these things (at least) 8 hours a day, but at the same time, they also get paid to keep users on their platform, thus not prioritising learning a language more quickly/efficiently (I think)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will try to find similar words between Swedish and French so that I can focus more on words that are completely different in my French-learning journey. The plan is also to extend this to include Spanish (another Romance language) which I am more proficient in. \n",
    "\n",
    "After having searched for a Swedish-French corpus without luck - I´ve settled on an English-French one for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/devicharith/language-translation-englishfrench\n",
      "License(s): CC0-1.0\n",
      "language-translation-englishfrench.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d devicharith/language-translation-englishfrench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define the path to the zip file and the extraction directory\n",
    "zip_file_path = \"language-translation-englishfrench.zip\" \n",
    "extraction_dir = \"language-translation-dataset\"\n",
    "\n",
    "# Create the extraction directory if it doesn't exist\n",
    "os.makedirs(extraction_dir, exist_ok=True)\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175616</th>\n",
       "      <td>Top-down economics never works, said Obama. \"T...</td>\n",
       "      <td>« L'économie en partant du haut vers le bas, ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175617</th>\n",
       "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
       "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175618</th>\n",
       "      <td>Death is something that we're often discourage...</td>\n",
       "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175619</th>\n",
       "      <td>Since there are usually multiple websites on a...</td>\n",
       "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175620</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175621 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  English words/sentences  \\\n",
       "0                                                     Hi.   \n",
       "1                                                    Run!   \n",
       "2                                                    Run!   \n",
       "3                                                    Who?   \n",
       "4                                                    Wow!   \n",
       "...                                                   ...   \n",
       "175616  Top-down economics never works, said Obama. \"T...   \n",
       "175617  A carbon footprint is the amount of carbon dio...   \n",
       "175618  Death is something that we're often discourage...   \n",
       "175619  Since there are usually multiple websites on a...   \n",
       "175620  If someone who doesn't know your background sa...   \n",
       "\n",
       "                                   French words/sentences  \n",
       "0                                                  Salut!  \n",
       "1                                                 Cours !  \n",
       "2                                                Courez !  \n",
       "3                                                   Qui ?  \n",
       "4                                              Ça alors !  \n",
       "...                                                   ...  \n",
       "175616  « L'économie en partant du haut vers le bas, ç...  \n",
       "175617  Une empreinte carbone est la somme de pollutio...  \n",
       "175618  La mort est une chose qu'on nous décourage sou...  \n",
       "175619  Puisqu'il y a de multiples sites web sur chaqu...  \n",
       "175620  Si quelqu'un qui ne connaît pas vos antécédent...  \n",
       "\n",
       "[175621 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset \n",
    "df = pd.read_csv(os.path.join(extraction_dir, 'eng_-french.csv')) \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['English'] = df['English words/sentences']\n",
    "df['French'] = df['French words/sentences']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright so it´s a sentence translation dataset. It´s alright - let´s work with this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let´s explore some of the similarities/differences between the \"shape\" of the two languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average English sentence length: 6.161552433934438\n",
      "Average French sentence length: 6.706669475746067\n"
     ]
    }
   ],
   "source": [
    "# Calculate average sentence lengths\n",
    "average_english_length = df['English'].str.split().str.len().mean()\n",
    "average_french_length = df['French'].str.split().str.len().mean()\n",
    "\n",
    "print(f\"Average English sentence length: {average_english_length}\")\n",
    "print(f\"Average French sentence length: {average_french_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaphone\n",
    "\n",
    "Metaphone is a phonetic algorithm for indexing words by their English pronounciation - it builds upon and improves on the Soundex algorithm. I´m looking at this quickly because I feel like my Swedish will help me more with improving my French pronounciation rather than English. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: metaphone in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install metaphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  English      French English_Phonetic French_Phonetic\n",
      "0     Hi.      Salut!               HH            SLTT\n",
      "1    Run!     Cours !              RNN           KRSSS\n",
      "2    Run!    Courez !              RNN           KRSSS\n",
      "3    Who?       Qui ?                A               K\n",
      "4    Wow!  Ça alors !                A          SLRSSS\n"
     ]
    }
   ],
   "source": [
    "from metaphone import doublemetaphone\n",
    "\n",
    "# Phonetic matching example\n",
    "def phonetic_similarity(word):\n",
    "    return doublemetaphone(word)[0]\n",
    "\n",
    "# Applying phonetic similarity to the first few English words\n",
    "df['English_Phonetic'] = df['English'].apply(phonetic_similarity)\n",
    "df['French_Phonetic'] = df['French'].apply(phonetic_similarity)\n",
    "\n",
    "# Comparing phonetic encodings\n",
    "print(df[['English', 'French', 'English_Phonetic', 'French_Phonetic']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I´ve read that the Jaccard similarity index can be used to measure the similarity e.g. between two text documents. I wonder if this is also the case for documents in two different languages. There might be some limitations to this but still interesting to look at.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>Jaccard_Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>Ignore Tom.</td>\n",
       "      <td>Ignore Tom.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71906</th>\n",
       "      <td>Tom has a terrible secret.</td>\n",
       "      <td>Tom a un terrible secret.</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21224</th>\n",
       "      <td>Tom has Windows 7.</td>\n",
       "      <td>Tom a Windows 7.</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12592</th>\n",
       "      <td>Tom has a ranch.</td>\n",
       "      <td>Tom a un ranch.</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9223</th>\n",
       "      <td>Tom has a Ford.</td>\n",
       "      <td>Tom a une Ford.</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60748</th>\n",
       "      <td>I brought reinforcements.</td>\n",
       "      <td>J'ai apporté des renforts.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60749</th>\n",
       "      <td>I brought you some lunch.</td>\n",
       "      <td>Je t'ai apporté un déjeuner.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60750</th>\n",
       "      <td>I brought you some lunch.</td>\n",
       "      <td>Je vous ai apporté un déjeuner.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60751</th>\n",
       "      <td>I brought you some water.</td>\n",
       "      <td>Je vous ai apporté de l'eau.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87810</th>\n",
       "      <td>Are they selling their house?</td>\n",
       "      <td>Ils vendent leur maison ?</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175621 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             English                           French  \\\n",
       "1460                     Ignore Tom.                      Ignore Tom.   \n",
       "71906     Tom has a terrible secret.        Tom a un terrible secret.   \n",
       "21224             Tom has Windows 7.                 Tom a Windows 7.   \n",
       "12592               Tom has a ranch.                  Tom a un ranch.   \n",
       "9223                 Tom has a Ford.                  Tom a une Ford.   \n",
       "...                              ...                              ...   \n",
       "60748      I brought reinforcements.       J'ai apporté des renforts.   \n",
       "60749      I brought you some lunch.     Je t'ai apporté un déjeuner.   \n",
       "60750      I brought you some lunch.  Je vous ai apporté un déjeuner.   \n",
       "60751      I brought you some water.     Je vous ai apporté de l'eau.   \n",
       "87810  Are they selling their house?        Ils vendent leur maison ?   \n",
       "\n",
       "       Jaccard_Similarity  \n",
       "1460             1.000000  \n",
       "71906            0.666667  \n",
       "21224            0.600000  \n",
       "12592            0.600000  \n",
       "9223             0.600000  \n",
       "...                   ...  \n",
       "60748            0.000000  \n",
       "60749            0.000000  \n",
       "60750            0.000000  \n",
       "60751            0.000000  \n",
       "87810            0.000000  \n",
       "\n",
       "[175621 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard_similarity(str1, str2):\n",
    "    a = set(str1.split())\n",
    "    b = set(str2.split())\n",
    "    return len(a.intersection(b)) / len(a.union(b))\n",
    "\n",
    "# Calculate Jaccard similarity between English and French sentences\n",
    "df['Jaccard_Similarity'] = df.apply(lambda x: jaccard_similarity(x['English'], x['French']), axis=1)\n",
    "\n",
    "# Display results\n",
    "df[['English', 'French', 'Jaccard_Similarity']].sort_values(by=['Jaccard_Similarity'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like it´s noticing similarities based on things that should be similar or the same. Such as names (Tom, Windows 7, Ford). Maybe we need to remove these. I don´t know how easy it is to kind of \"reverse engineer\" this and go from this to an english-french dictionary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Richness of vocabulary\n",
    "\n",
    "Let´s look at the number of unique words in both columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in English: 25622\n",
      "Unique words in French: 42627\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to extract unique words from a column\n",
    "def unique_words(column):\n",
    "    # Split each sentence into words, convert to lowercase, and create a set to find unique words\n",
    "    words = column.str.cat(sep=' ').lower().split()\n",
    "    return set(words)\n",
    "\n",
    "# Extract unique words from both columns\n",
    "unique_english = unique_words(df['English'])\n",
    "unique_french = unique_words(df['French'])\n",
    "\n",
    "# Count unique words\n",
    "count_unique_english = len(unique_english)\n",
    "count_unique_french = len(unique_french)\n",
    "\n",
    "# Print results\n",
    "print(f\"Unique words in English: {count_unique_english}\")\n",
    "print(f\"Unique words in French: {count_unique_french}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
